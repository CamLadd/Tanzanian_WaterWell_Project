{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Summary and Goal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tanzania, as a developing country, struggles with providing clean water to its population of over 57,000,000. There are many waterpoints already established in the country, but some are in need of repair while others have failed altogether."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build a classifier to predict the condition of a water well, using information provided in the data. This information includes:\n",
    "- Date\n",
    "- Location\n",
    "- Source\n",
    "- Funder\n",
    "- And more!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This data is from the DrivenData.org website. It is part of the \"Pump It Up: Data Mining the Water Table\" dfetition. DrivenData decided to split the data up into two sets, the \"Training Set\" and the \"Test Set\". \n",
    "\n",
    "It is implied by the names that we are to use the training set for creating our models, and the test set to test them. For this project, we considered merging the two dataframes in order to have more data to work with, however there are 59,400 entries in the training set and therefore more than enough to make good predicitons. \n",
    "\n",
    "If our models are subpar, we may merge the tables to aquire more data points to potentially improve model efficacy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning and Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of dataset: (59400, 41)\n"
     ]
    },
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>amount_tsh</th>\n      <th>date_recorded</th>\n      <th>funder</th>\n      <th>gps_height</th>\n      <th>installer</th>\n      <th>longitude</th>\n      <th>latitude</th>\n      <th>wpt_name</th>\n      <th>num_private</th>\n      <th>...</th>\n      <th>water_quality</th>\n      <th>quality_group</th>\n      <th>quantity</th>\n      <th>quantity_group</th>\n      <th>source</th>\n      <th>source_type</th>\n      <th>source_class</th>\n      <th>waterpoint_type</th>\n      <th>waterpoint_type_group</th>\n      <th>status_group</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>69572</td>\n      <td>6000.0</td>\n      <td>2011-03-14</td>\n      <td>Roman</td>\n      <td>1390</td>\n      <td>Roman</td>\n      <td>34.938093</td>\n      <td>-9.856322</td>\n      <td>none</td>\n      <td>0</td>\n      <td>...</td>\n      <td>soft</td>\n      <td>good</td>\n      <td>enough</td>\n      <td>enough</td>\n      <td>spring</td>\n      <td>spring</td>\n      <td>groundwater</td>\n      <td>communal standpipe</td>\n      <td>communal standpipe</td>\n      <td>functional</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>8776</td>\n      <td>0.0</td>\n      <td>2013-03-06</td>\n      <td>Grumeti</td>\n      <td>1399</td>\n      <td>GRUMETI</td>\n      <td>34.698766</td>\n      <td>-2.147466</td>\n      <td>Zahanati</td>\n      <td>0</td>\n      <td>...</td>\n      <td>soft</td>\n      <td>good</td>\n      <td>insufficient</td>\n      <td>insufficient</td>\n      <td>rainwater harvesting</td>\n      <td>rainwater harvesting</td>\n      <td>surface</td>\n      <td>communal standpipe</td>\n      <td>communal standpipe</td>\n      <td>functional</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>34310</td>\n      <td>25.0</td>\n      <td>2013-02-25</td>\n      <td>Lottery Club</td>\n      <td>686</td>\n      <td>World vision</td>\n      <td>37.460664</td>\n      <td>-3.821329</td>\n      <td>Kwa Mahundi</td>\n      <td>0</td>\n      <td>...</td>\n      <td>soft</td>\n      <td>good</td>\n      <td>enough</td>\n      <td>enough</td>\n      <td>dam</td>\n      <td>dam</td>\n      <td>surface</td>\n      <td>communal standpipe multiple</td>\n      <td>communal standpipe</td>\n      <td>functional</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>67743</td>\n      <td>0.0</td>\n      <td>2013-01-28</td>\n      <td>Unicef</td>\n      <td>263</td>\n      <td>UNICEF</td>\n      <td>38.486161</td>\n      <td>-11.155298</td>\n      <td>Zahanati Ya Nanyumbu</td>\n      <td>0</td>\n      <td>...</td>\n      <td>soft</td>\n      <td>good</td>\n      <td>dry</td>\n      <td>dry</td>\n      <td>machine dbh</td>\n      <td>borehole</td>\n      <td>groundwater</td>\n      <td>communal standpipe multiple</td>\n      <td>communal standpipe</td>\n      <td>non functional</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>19728</td>\n      <td>0.0</td>\n      <td>2011-07-13</td>\n      <td>Action In A</td>\n      <td>0</td>\n      <td>Artisan</td>\n      <td>31.130847</td>\n      <td>-1.825359</td>\n      <td>Shuleni</td>\n      <td>0</td>\n      <td>...</td>\n      <td>soft</td>\n      <td>good</td>\n      <td>seasonal</td>\n      <td>seasonal</td>\n      <td>rainwater harvesting</td>\n      <td>rainwater harvesting</td>\n      <td>surface</td>\n      <td>communal standpipe</td>\n      <td>communal standpipe</td>\n      <td>functional</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 41 columns</p>\n</div>",
      "text/plain": "      id  amount_tsh date_recorded        funder  gps_height     installer  \\\n0  69572      6000.0    2011-03-14         Roman        1390         Roman   \n1   8776         0.0    2013-03-06       Grumeti        1399       GRUMETI   \n2  34310        25.0    2013-02-25  Lottery Club         686  World vision   \n3  67743         0.0    2013-01-28        Unicef         263        UNICEF   \n4  19728         0.0    2011-07-13   Action In A           0       Artisan   \n\n   longitude   latitude              wpt_name  num_private  ... water_quality  \\\n0  34.938093  -9.856322                  none            0  ...          soft   \n1  34.698766  -2.147466              Zahanati            0  ...          soft   \n2  37.460664  -3.821329           Kwa Mahundi            0  ...          soft   \n3  38.486161 -11.155298  Zahanati Ya Nanyumbu            0  ...          soft   \n4  31.130847  -1.825359               Shuleni            0  ...          soft   \n\n  quality_group      quantity  quantity_group                source  \\\n0          good        enough          enough                spring   \n1          good  insufficient    insufficient  rainwater harvesting   \n2          good        enough          enough                   dam   \n3          good           dry             dry           machine dbh   \n4          good      seasonal        seasonal  rainwater harvesting   \n\n            source_type source_class              waterpoint_type  \\\n0                spring  groundwater           communal standpipe   \n1  rainwater harvesting      surface           communal standpipe   \n2                   dam      surface  communal standpipe multiple   \n3              borehole  groundwater  communal standpipe multiple   \n4  rainwater harvesting      surface           communal standpipe   \n\n  waterpoint_type_group    status_group  \n0    communal standpipe      functional  \n1    communal standpipe      functional  \n2    communal standpipe      functional  \n3    communal standpipe  non functional  \n4    communal standpipe      functional  \n\n[5 rows x 41 columns]"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import Pandas\r\n",
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "import math\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import seaborn as sns\r\n",
    "%matplotlib inline\r\n",
    "\r\n",
    "# ignore all future warnings\r\n",
    "from warnings import simplefilter\r\n",
    "simplefilter(action='ignore', category=FutureWarning)\r\n",
    "\r\n",
    "# Load data into  Pandas dataframes\r\n",
    "status_groups = pd.read_csv('status_groups.csv')\r\n",
    "testset = pd.read_csv('test_set.csv')\r\n",
    "df = pd.read_csv('training_set.csv')\r\n",
    "\r\n",
    "\r\n",
    "# Let's add our target series to the dataframe!\r\n",
    "status_groups.drop(['id'], axis=1, inplace=True)\r\n",
    "df = pd.concat([df, status_groups], axis=1)\r\n",
    "\r\n",
    "# Analyze shape of dataset\r\n",
    "print(f'Shape of dataset: {df.shape}')\r\n",
    "display(df.head())\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "Index(['id', 'amount_tsh', 'date_recorded', 'funder', 'gps_height',\n       'installer', 'longitude', 'latitude', 'wpt_name', 'num_private',\n       'basin', 'subvillage', 'region', 'region_code', 'district_code', 'lga',\n       'ward', 'population', 'public_meeting', 'recorded_by',\n       'scheme_management', 'scheme_name', 'permit', 'construction_year',\n       'extraction_type', 'extraction_type_group', 'extraction_type_class',\n       'management', 'management_group', 'payment', 'payment_type',\n       'water_quality', 'quality_group', 'quantity', 'quantity_group',\n       'source', 'source_type', 'source_class', 'waterpoint_type',\n       'waterpoint_type_group', 'status_group'],\n      dtype='object')"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array(['Lake Nyasa', 'Lake Victoria', 'Pangani',\n       'Ruvuma / Southern Coast', 'Internal', 'Lake Tanganyika',\n       'Wami / Ruvu', 'Rufiji', 'Lake Rukwa'], dtype=object)"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.basin.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop unneeded columns and deal with missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "funder                3635\ninstaller             3655\nsubvillage             371\npublic_meeting        3334\nscheme_management     3877\nscheme_name          28166\npermit                3056\ndtype: int64"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# EXPLORATORY! We are analyzing the columns in order to remove redundancies\r\n",
    "# **Uncomment if viewing the unique values is desired**\r\n",
    "\r\n",
    "# df.region.unique()\r\n",
    "# df.scheme_management\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "# display(df.water_quality.unique())\r\n",
    "# display(df.quality_group.unique())\r\n",
    "\r\n",
    "# display(df.management.unique())\r\n",
    "# display(df.management_group.unique())\r\n",
    "\r\n",
    "# display(df.payment.unique())\r\n",
    "# display(df.payment_type.unique())\r\n",
    "\r\n",
    "# display(df.quantity.unique())\r\n",
    "# display(df.quantity_group.unique())\r\n",
    "\r\n",
    "df.isna().sum()[df.isna().sum()>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display(df.waterpoint_type.unique())\r\n",
    "# display(df.waterpoint_type_group.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array(['gravity', 'submersible', 'handpump', 'other', 'motorpump',\n       'wind-powered', 'rope pump'], dtype=object)"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "array(['gravity', 'submersible', 'swn 80', 'nira/tanira', 'india mark ii',\n       'other', 'ksb', 'mono', 'windmill', 'afridev', 'other - rope pump',\n       'india mark iii', 'other - swn 81', 'other - play pump', 'cemo',\n       'climax', 'walimi', 'other - mkulima/shinyanga'], dtype=object)"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "array(['gravity', 'submersible', 'swn 80', 'nira/tanira', 'india mark ii',\n       'other', 'mono', 'wind-powered', 'afridev', 'rope pump',\n       'india mark iii', 'other handpump', 'other motorpump'],\n      dtype=object)"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df['extraction_type_class'].unique())\r\n",
    "display(df['extraction_type'].unique())\r\n",
    "display(df['extraction_type_group'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The three 'extraction_type' columns display the same information, however both 'extraction_type' and 'extraction_type_group' have many more unique values than 'extraction_type_class'. When looking at the columns, it is clear that 'extraction_type_class' is more interpretable, and reduces the cardinality of this 'extraction_type' data considerably, without reducing its effectiveness in conveying the information it intends to. For this reason, we will be keeping 'extraction_type_class' and dropping the others."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "display(df['source_class'].unique())\r\n",
    "display(df['source'].unique())\r\n",
    "display(df['source_type'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The three 'source' columns provide the same information, with 'source_class' being the least specific and 'source' being the most specific. In order to make sure we have enough cardinality, but not too much, we have chosen to keep the 'source_type' column, because it provides a easily interpretable representation of the source information without having so many categories that it is confusing, or to little so that it is vague."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label encode the target variable\r\n",
    "status_labels = {'status_group':{'non functional': 0, 'functional': 1, 'functional needs repair': 2}}\r\n",
    "df = df.replace(status_labels)\r\n",
    "df.status_group.value_counts()\r\n",
    "\r\n",
    "\r\n",
    "# Drop redundant and unneeded columns\r\n",
    "to_drop = ['scheme_name', 'recorded_by', 'wpt_name', 'extraction_type', 'extraction_type_group',\r\n",
    "           'region_code', 'district_code', 'lga', 'ward', 'public_meeting', 'date_recorded', \r\n",
    "           'source', 'source_class', 'waterpoint_type', 'water_quality', 'management_group', \r\n",
    "           'payment', 'quantity_group','subvillage', 'num_private', 'scheme_management']\r\n",
    "\r\n",
    "\r\n",
    "# Deal with missing values\r\n",
    "df.drop(to_drop, axis=1, inplace=True)\r\n",
    "df.permit.fillna(False, inplace=True)\r\n",
    "df.dropna(axis=0, inplace=True)\r\n",
    "\r\n",
    "# Set 'id' as the index of the dataframe\r\n",
    "df.set_index('id', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grouping and Labeling Column Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "Government Of Tanzania    9080\nDanida                    3114\nHesawa                    2197\nRwssp                     1373\nWorld Bank                1338\nKkkt                      1287\nWorld Vision              1239\nUnicef                    1057\nTasaf                      876\nDistrict Council           842\nDhv                        829\nPrivate Individual         826\nDwsp                       811\nunknown                    777\nNorad                      764\nGermany Republi            610\nTcrs                       601\nMinistry Of Water          586\nWater                      583\nDwe                        484\nName: funder, dtype: int64"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Funder\n",
    "df.funder.replace(to_replace='0', value='unknown', inplace=True)\n",
    "df.funder.value_counts().head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "other = list(df.funder[df['funder'].map(df['funder'].value_counts()) < 484].values)\r\n",
    "other\r\n",
    "df['funder'].replace(other, 'other', inplace=True)\r\n",
    "\r\n",
    "df.funder.replace(to_replace='0', value='Unknown', inplace=True)\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installer\n",
    "\n",
    "other = list(df.installer[df['installer'].map(df['installer'].value_counts()) < 392].values)\n",
    "other\n",
    "df['installer'].replace(other, 'other', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Permit\n",
    "\n",
    "df.permit.replace({True:1, False:0}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Population\n",
    "    \n",
    "def population(obs):\n",
    "    s=''\n",
    "    x=obs['population']\n",
    "    if(0<x<=100):\n",
    "        s='Less than 100'\n",
    "    elif(100<x<=200):\n",
    "        s='Between 100 and 200'\n",
    "    elif(200<x<=300):\n",
    "        s='Between 200 and 300'\n",
    "    elif(300<x<=400):\n",
    "        s='between 300 and 400'\n",
    "    elif(400<x<=500):\n",
    "        s='between 400 and 500'\n",
    "    elif(500<x):\n",
    "        s='Over 500'\n",
    "    elif(x==0):\n",
    "        s='No population'\n",
    "    return s\n",
    "df['population']=df.apply(population,axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construction year\r\n",
    "\r\n",
    "from datetime import datetime\r\n",
    "df['date_recorded'] = pd.to_datetime(df['date_recorded'])\r\n",
    "\r\n",
    "\r\n",
    "conditions = [df['construction_year']==0, (df['construction_year']>=1960)&(df['construction_year']<=1970), (df['construction_year']>1970)&(df['construction_year']<=1980),\r\n",
    "            (df['construction_year']>1980)&(df['construction_year']<=1990), (df['construction_year']>1990)&(df['construction_year']<=2000),\r\n",
    "            (df['construction_year']>2000)&(df['construction_year']<=2010), df['construction_year']>2010]\r\n",
    "choices = ['no_construction_year', '1960_1970', '1971_1980', '1981_1990', '1991_2000', '2001_2010', '2011_over']\r\n",
    "df['construction_year'] = np.select(conditions, choices)\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Amount_tsh\n",
    "# Bin\n",
    "conditions = [df.amount_tsh==0,(df.amount_tsh>0)&(df.amount_tsh<=10),(df.amount_tsh>10)&(df.amount_tsh<=100), (df.amount_tsh>100)&(df.amount_tsh<=1000),\n",
    "             (df.amount_tsh>1000)&(df.amount_tsh<=2000), (df.amount_tsh>2000)&(df.amount_tsh<=10000), (df.amount_tsh>10000)&(df.amount_tsh<=100000),\n",
    "             df.amount_tsh>100000]\n",
    "choices = ['zero', '1 to 10', '11 to 100', '101 to 1k', '1k to 2k', '2k to 10k', '10k to 100k', 'greater than 100k']\n",
    "df['amount_tsh'] = np.select(conditions, choices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.gps_height = pd.qcut(df.gps_height, 8, duplicates='drop', \n",
    "        labels=['-90m - sea level', 'sea level to 46m', '46m to 393m', '393m to 1017m', '1017m to 1316m', '1316m to 1586.75m', '1586.75m to 2770m'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.loc[df['funder']== 'Government Of Tanzania']\r\n",
    "df2 = df.loc[df['funder']== 'Tasaf']              \r\n",
    "df3 = df.loc[df['funder']== 'Danida'] \r\n",
    "df4 = df.loc[df['funder']== 'Hesawa'] \r\n",
    "df5 = df.loc[df['funder']== 'Rwssp'] \r\n",
    "df6 = df.loc[df['funder']== 'World Bank'] \r\n",
    "df7 = df.loc[df['funder']== 'Kkkt'] \r\n",
    "df8 = df.loc[df['funder']== 'World Vision']\r\n",
    "df9 = df.loc[df['funder']== 'Unicef'] \r\n",
    "df10 = df.loc[df['funder']== 'unknown'] \r\n",
    "df11 = df.loc[df['funder']== 'District Council'] \r\n",
    "df12 = df.loc[df['funder']== 'Dhv'] \r\n",
    "df13 = df.loc[df['funder']== 'Private Individual'] \r\n",
    "df14 = df.loc[df['funder']== 'Dwsp'] \r\n",
    "df15 = df.loc[df['funder']== 'Norad'] \r\n",
    "df16 = df.loc[df['funder']== 'Germany Republi']\r\n",
    "df17 = df.loc[df['funder']== 'Tcrs']\r\n",
    "df18 = df.loc[df['funder']== 'Ministry Of Water']\r\n",
    "df19 = df.loc[df['funder']== 'Water']\r\n",
    "df20 = df.loc[df['funder']== 'Dwe']\r\n",
    "\r\n",
    "top_20 = pd.concat([df1,df2,df3,df4,df5,df6,df7,df8,df9,df10,df11,df12,\r\n",
    "                    df13,df14,df15,df16,df17,df18,df19,df20], ignore_index=True)\r\n",
    "\r\n",
    "fig, ax = plt.subplots(figsize=(20,20))\r\n",
    "sns.countplot(x='funder', hue=\"status_group\", data=top_20)\r\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(25,25))\n",
    "sns.countplot(x='funder', hue='status_group', data=df)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,12))\r\n",
    "sns.scatterplot(x='latitude', y='longitude', hue='status_group',data=df)\r\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,12))\n",
    "sns.countplot(x='waterpoint_type_group', hue='status_group', data=df)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,12))\n",
    "sns.countplot(x='source_type', hue='status_group', data=df)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,12))\n",
    "sns.countplot(x='quality_group', hue='status_group', data=df)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,12))\n",
    "sns.countplot(x='payment_type', hue='status_group', data=df)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,12))\n",
    "sns.countplot(x='construction_year', hue='status_group', data=df)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,12))\n",
    "sns.countplot(x='population', hue='status_group', data=df)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(6,6))\n",
    "sns.countplot(x='quantity', hue='status_group', data=df)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15,15))\n",
    "sns.countplot(x='region', hue='status_group', data=df)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,12))\n",
    "sns.countplot(x='management', hue='status_group', data=df)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "sns.countplot(x='amount_tsh', hue='status_group', data=df)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15,15))\n",
    "sns.countplot(x='basin', hue='status_group', data=df)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(6,6))\n",
    "sns.countplot(x='permit', hue='status_group', data=df)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.status_group.value_counts().plot(kind='bar', color='orange')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries/Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\r\n",
    "from sklearn.impute import MissingIndicator, SimpleImputer\r\n",
    "from sklearn.dummy import DummyClassifier\r\n",
    "from sklearn.linear_model import LogisticRegression\r\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_validate\r\n",
    "from sklearn.feature_selection import SelectFromModel\r\n",
    "from xgboost import XGBClassifier\r\n",
    "from sklearn.naive_bayes import MultinomialNB\r\n",
    "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier\r\n",
    "from sklearn.tree import DecisionTreeClassifier\r\n",
    "from sklearn.svm import SVC\r\n",
    "from sklearn.feature_selection import RFE\r\n",
    "\r\n",
    "# plot_confusion_matrix is a handy visual tool, added in the latest version of scikit-learn\r\n",
    "# if you are running an older version, comment out this line and just use confusion_matrix\r\n",
    "\r\n",
    "from sklearn.metrics import plot_confusion_matrix\r\n",
    "from sklearn.metrics import confusion_matrix\r\n",
    "from sklearn.metrics import plot_roc_curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define X and y, Dummy, OneHotEncode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify features and target\r\n",
    "features = df.drop('status_group', axis=1)\r\n",
    "target = df.status_group\r\n",
    "\r\n",
    "# Dummy the features\r\n",
    "features_dummied = pd.get_dummies(features, drop_first=True)\r\n",
    "features_dummied.head()\r\n",
    "\r\n",
    "# OneHotEncode the features\r\n",
    "encoder = OneHotEncoder()\r\n",
    "features_ohe = encoder.fit_transform(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and test sets\r\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_ohe, target, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "0.7769997306760033"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build model\r\n",
    "tree = DecisionTreeClassifier(random_state=123)\r\n",
    "\r\n",
    "# Train model\r\n",
    "tree.fit(X_train, y_train)\r\n",
    "\r\n",
    "# Score model\r\n",
    "tree.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and test sets\r\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_ohe, target, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "0.5424185294909777"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build model\r\n",
    "forest = RandomForestClassifier(random_state=123)\r\n",
    "\r\n",
    "# Train model\r\n",
    "forest.fit(X_train, y_train)\r\n",
    "\r\n",
    "# Score model\r\n",
    "forest.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and test sets\r\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_ohe, target, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "0.7141574647634438"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build model\r\n",
    "nb = MultinomialNB()\r\n",
    "\r\n",
    "# Train model\r\n",
    "nb.fit(X_train, y_train)\r\n",
    "\r\n",
    "# Score model\r\n",
    "nb.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and test sets\r\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_ohe, target, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "0.7859771972349403"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build model\r\n",
    "xg = XGBClassifier(random_state=123)\r\n",
    "\r\n",
    "# Train model\r\n",
    "xg.fit(X_train, y_train)\r\n",
    "\r\n",
    "# Score model\r\n",
    "xg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and test sets\r\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_ohe, target, test_size=0.2, random_state=123)\r\n",
    "\r\n",
    "# Recursive feature elimination\r\n",
    "rfe = RFE(SVC(), n_features_to_select = 20)\r\n",
    "rfe = rfe.fit(X_train, y_train)\r\n",
    "rfe_columns = pd.Series(X_train.columns)\r\n",
    "rfe_code = pd.Series(rfe.support_)\r\n",
    "columns_to_keep = pd.concat([rfe_columns, rfe_code], axis=1)\r\n",
    "rfe_X_train = X_train[list(columns_to_keep[columns_to_keep[1]==True][0])]\r\n",
    "rfe_X_test = X_test[list(columns_to_keep[columns_to_keep[1]==True][0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "0.5407128108447796"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build model\r\n",
    "svc = SVC(random_state=123, gamma='auto')\r\n",
    "\r\n",
    "# Train model\r\n",
    "svc.fit(X_train, y_train)\r\n",
    "\r\n",
    "# Score model\r\n",
    "svc.score(X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "02a9839076075b91ad0ca4473d7f7ceb754ea3983ec7c01053cc622904b7a0ac"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('learn-env': conda)",
   "name": "python385jvsc74a57bd002a9839076075b91ad0ca4473d7f7ceb754ea3983ec7c01053cc622904b7a0ac"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}