{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Summary and Goal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tanzania, as a developing country, struggles with providing clean water to its population of over 57,000,000. There are many waterpoints already established in the country, but some are in need of repair while others have failed altogether."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build a classifier to predict the condition of a water well, using information provided in the data. This information includes:\n",
    "- Date\n",
    "- Location\n",
    "- Source\n",
    "- Funder\n",
    "- And more!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This data is from the DrivenData.org website. It is part of the \"Pump It Up: Data Mining the Water Table\" dfetition. DrivenData decided to split the data up into two sets, the \"Training Set\" and the \"Test Set\". \n",
    "\n",
    "It is implied by the names that we are to use the training set for creating our models, and the test set to test them. For this project, we considered merging the two dataframes in order to have more data to work with, however there are 59,400 entries in the training set and therefore more than enough to make good predicitons. \n",
    "\n",
    "If our models are subpar, we may merge the tables to aquire more data points to potentially improve model efficacy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning and Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install category_encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of dataset: (59400, 41)\n"
     ]
    },
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>amount_tsh</th>\n      <th>date_recorded</th>\n      <th>funder</th>\n      <th>gps_height</th>\n      <th>installer</th>\n      <th>longitude</th>\n      <th>latitude</th>\n      <th>wpt_name</th>\n      <th>num_private</th>\n      <th>...</th>\n      <th>water_quality</th>\n      <th>quality_group</th>\n      <th>quantity</th>\n      <th>quantity_group</th>\n      <th>source</th>\n      <th>source_type</th>\n      <th>source_class</th>\n      <th>waterpoint_type</th>\n      <th>waterpoint_type_group</th>\n      <th>status_group</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>69572</td>\n      <td>6000.0</td>\n      <td>2011-03-14</td>\n      <td>Roman</td>\n      <td>1390</td>\n      <td>Roman</td>\n      <td>34.938093</td>\n      <td>-9.856322</td>\n      <td>none</td>\n      <td>0</td>\n      <td>...</td>\n      <td>soft</td>\n      <td>good</td>\n      <td>enough</td>\n      <td>enough</td>\n      <td>spring</td>\n      <td>spring</td>\n      <td>groundwater</td>\n      <td>communal standpipe</td>\n      <td>communal standpipe</td>\n      <td>functional</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>8776</td>\n      <td>0.0</td>\n      <td>2013-03-06</td>\n      <td>Grumeti</td>\n      <td>1399</td>\n      <td>GRUMETI</td>\n      <td>34.698766</td>\n      <td>-2.147466</td>\n      <td>Zahanati</td>\n      <td>0</td>\n      <td>...</td>\n      <td>soft</td>\n      <td>good</td>\n      <td>insufficient</td>\n      <td>insufficient</td>\n      <td>rainwater harvesting</td>\n      <td>rainwater harvesting</td>\n      <td>surface</td>\n      <td>communal standpipe</td>\n      <td>communal standpipe</td>\n      <td>functional</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>34310</td>\n      <td>25.0</td>\n      <td>2013-02-25</td>\n      <td>Lottery Club</td>\n      <td>686</td>\n      <td>World vision</td>\n      <td>37.460664</td>\n      <td>-3.821329</td>\n      <td>Kwa Mahundi</td>\n      <td>0</td>\n      <td>...</td>\n      <td>soft</td>\n      <td>good</td>\n      <td>enough</td>\n      <td>enough</td>\n      <td>dam</td>\n      <td>dam</td>\n      <td>surface</td>\n      <td>communal standpipe multiple</td>\n      <td>communal standpipe</td>\n      <td>functional</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>67743</td>\n      <td>0.0</td>\n      <td>2013-01-28</td>\n      <td>Unicef</td>\n      <td>263</td>\n      <td>UNICEF</td>\n      <td>38.486161</td>\n      <td>-11.155298</td>\n      <td>Zahanati Ya Nanyumbu</td>\n      <td>0</td>\n      <td>...</td>\n      <td>soft</td>\n      <td>good</td>\n      <td>dry</td>\n      <td>dry</td>\n      <td>machine dbh</td>\n      <td>borehole</td>\n      <td>groundwater</td>\n      <td>communal standpipe multiple</td>\n      <td>communal standpipe</td>\n      <td>non functional</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>19728</td>\n      <td>0.0</td>\n      <td>2011-07-13</td>\n      <td>Action In A</td>\n      <td>0</td>\n      <td>Artisan</td>\n      <td>31.130847</td>\n      <td>-1.825359</td>\n      <td>Shuleni</td>\n      <td>0</td>\n      <td>...</td>\n      <td>soft</td>\n      <td>good</td>\n      <td>seasonal</td>\n      <td>seasonal</td>\n      <td>rainwater harvesting</td>\n      <td>rainwater harvesting</td>\n      <td>surface</td>\n      <td>communal standpipe</td>\n      <td>communal standpipe</td>\n      <td>functional</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 41 columns</p>\n</div>",
      "text/plain": "      id  amount_tsh date_recorded        funder  gps_height     installer  \\\n0  69572      6000.0    2011-03-14         Roman        1390         Roman   \n1   8776         0.0    2013-03-06       Grumeti        1399       GRUMETI   \n2  34310        25.0    2013-02-25  Lottery Club         686  World vision   \n3  67743         0.0    2013-01-28        Unicef         263        UNICEF   \n4  19728         0.0    2011-07-13   Action In A           0       Artisan   \n\n   longitude   latitude              wpt_name  num_private  ... water_quality  \\\n0  34.938093  -9.856322                  none            0  ...          soft   \n1  34.698766  -2.147466              Zahanati            0  ...          soft   \n2  37.460664  -3.821329           Kwa Mahundi            0  ...          soft   \n3  38.486161 -11.155298  Zahanati Ya Nanyumbu            0  ...          soft   \n4  31.130847  -1.825359               Shuleni            0  ...          soft   \n\n  quality_group      quantity  quantity_group                source  \\\n0          good        enough          enough                spring   \n1          good  insufficient    insufficient  rainwater harvesting   \n2          good        enough          enough                   dam   \n3          good           dry             dry           machine dbh   \n4          good      seasonal        seasonal  rainwater harvesting   \n\n            source_type source_class              waterpoint_type  \\\n0                spring  groundwater           communal standpipe   \n1  rainwater harvesting      surface           communal standpipe   \n2                   dam      surface  communal standpipe multiple   \n3              borehole  groundwater  communal standpipe multiple   \n4  rainwater harvesting      surface           communal standpipe   \n\n  waterpoint_type_group    status_group  \n0    communal standpipe      functional  \n1    communal standpipe      functional  \n2    communal standpipe      functional  \n3    communal standpipe  non functional  \n4    communal standpipe      functional  \n\n[5 rows x 41 columns]"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import Pandas\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "# ignore all future warnings\n",
    "from warnings import simplefilter\n",
    "simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "# Load data into  Pandas dataframes\n",
    "status_groups = pd.read_csv('status_groups.csv')\n",
    "testset = pd.read_csv('test_set.csv')\n",
    "df = pd.read_csv('training_set.csv')\n",
    "\n",
    "\n",
    "# Let's add our target series to the dataframe!\n",
    "status_groups.drop(['id'], axis=1, inplace=True)\n",
    "df = pd.concat([df, status_groups], axis=1)\n",
    "\n",
    "# Analyze shape of dataset\n",
    "print(f'Shape of dataset: {df.shape}')\n",
    "display(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PERMIT ------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15,15))\n",
    "sns.countplot(x='permit', hue='status_group', data=df)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wells with permits have a larger functional to non-functional ration than those without."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "REGION ------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15,15))\n",
    "sns.countplot(x='region', hue='status_group', data=df)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Region can be a good indicator of well status, because how many functional vs non-functional wells differ a lot from region to region. For example, if you were to pick a well at random in the region 'Iringa', you would most likely find a functional well, but if you picked a well at random in 'Mtwara', you would most likely find a non-functional well!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BASIN ------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15,15))\n",
    "sns.countplot(x='basin', hue='status_group', data=df)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are some basins that are clearly more successful when establishing wells. Two regions that stick out are 'Ruvuma/Southern Coast' and 'Lake Rukwa', because both of those basins seem to have a majority non-functional wells!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** Since we are keeping basin, region, and latitude and longitude, we do not need any more columns that provide location data or it would become to noisy. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CONSTRUCTION YEAR -------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15,15))\n",
    "sns.countplot(x='construction_year', hue='status_group', data=df)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When ignoring the data of contruction_year==0, we can clearly see that newer wells are functional more often, while older wells are non-functional more often."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MANAGEMENT ------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df.management.unique())\n",
    "display(df.management_group.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15,15))\n",
    "sns.countplot(x='management', hue='status_group', data=df)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15,15))\n",
    "sns.countplot(x='management_group', hue='status_group', data=df)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both columns provide the same data however 'management' is more detailed, so we will keep that column and drop the other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PAYMENT ------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df.payment.unique())\n",
    "display(df.payment_type.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15,15))\n",
    "sns.countplot(x='payment', hue='status_group', data=df)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15,15))\n",
    "sns.countplot(x='payment_type', hue='status_group', data=df)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'payment' and 'payment_type' are columns with identical data. We can drop one. We will drop 'payment'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "QUANTITY ------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df.quantity.unique())\n",
    "display(df.quantity_group.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15,15))\n",
    "sns.countplot(x='quantity', hue='status_group', data=df)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15,15))\n",
    "sns.countplot(x='quantity_group', hue='status_group', data=df)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'quantity_group' and 'quantity' are identical columns. We can drop one, and we will drop 'quantity_group' because 'qauntity' is a title that is understood easier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WATERPOINT TYPE ------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df.waterpoint_type.unique())\n",
    "display(df.waterpoint_type_group.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15,15))\n",
    "sns.countplot(x='waterpoint_type_group', hue='status_group', data=df)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15,15))\n",
    "sns.countplot(x='waterpoint_type', hue='status_group', data=df)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two 'waterpoint_type' columns display redundant information. 'waterpoint_type' is more desireable because there are very noticeable difference between the two groups that 'waterpoint_type_group' joined; 'communal standpoint' and 'communal standpoint multiple'. The majority of wells with a waterpoint type of 'communal standpoint multiple' were non-functional, while the majority of wells with a waterpoint type of 'communal standpoint' were functional. This is an important difference we wish to express."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall, handpumps and communal standpoints (and to a lesser extent, improved spring) show a majority occurence of functional wells, while the rest show a majority occurence of non-functional wells"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EXTRACTION TYPE ------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df['extraction_type_class'].unique())\n",
    "display(df['extraction_type'].unique())\n",
    "display(df['extraction_type_group'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,12))\n",
    "sns.countplot(x='extraction_type_class', hue='status_group', data=df)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The three 'extraction_type' columns display the same information, however both 'extraction_type' and 'extraction_type_group' have many more unique values than 'extraction_type_class'. When looking at the columns, it is clear that 'extraction_type_class' is more interpretable, and reduces the cardinality of this 'extraction_type' data considerably, without reducing its effectiveness in conveying the information it intends to. For this reason, we will be keeping 'extraction_type_class' and dropping the others."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall, the data of wells that use a gravity and handpump extraction type have the highest occurence of functional wells, while motorpump and other extraction type are most likely to be non-functional in comparison. Submersible also has a majority functional, however it is not as pronounced as handpump and gravity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SOURCE  ------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df['source_class'].unique())\n",
    "display(df['source'].unique())\n",
    "display(df['source_type'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,12))\n",
    "sns.countplot(x='source', hue='status_group', data=df)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,12))\n",
    "sns.countplot(x='source_type', hue='status_group', data=df)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The three 'source' columns provide the same information, with 'source_class' being the least specific and 'source' being the most specific. 'Source' provides mroe detailed information without severely increasing cardinality, and therefore we will keep that column and drop the others."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Springs, rainwater harvesting, shallow wells, rivers, DBH machines, and hand boreholes (hand dtw) are most likely to be functional in comparison to the other source types. Noticeably, wells with their source as a river are functional significantly more often than if the source is a lake. This information was not conveyed in the 'source_type' column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "QUALITY ------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df.water_quality.unique())\n",
    "display(df.quality_group.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,12))\n",
    "sns.countplot(x='water_quality', hue='status_group', data=df)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,12))\n",
    "sns.countplot(x='quality_group', hue='status_group', data=df)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 'water_quality' and 'quality_group' columns provide redundant information. 'quality_group' is more desireable than 'quality_group' even though the latter is more specific because the latter's specificity does not add any meaninful information to our analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Water of 'good' quality results in mostly functional wells, while those classified as an 'unknown' quality are mostly non-functional. They are unknown potentially due to the well being out of commission for such a long time that the water quality was no longer known by the time of recording."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AMOUNT_TSH -----------------------------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.amount_tsh.value_counts().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.amount_tsh.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Percentage of data that is zero: {41639/59400}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The amount_tsh column describes the 'Total Static Head' of each well, which is defined as “The vertical height of a stationary column of liquid produced by a pump, measured from the suction level\". This information could be useful for clasification, however 70% of all the values given are 0. We are unable to determine if the TSH level of these wells are actually zero, or if the number was simply used as a placeholder to describe a lack of information or a specific TSH status. Due to this, we will be dropping the column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop Columns and Deal with Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "location = df[['latitude', 'longitude']]\r\n",
    "location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()[df.isna().sum()>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['latitiude'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-d05209e561fd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;31m# Deal with missing values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mto_drop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpermit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4161\u001b[0m                 \u001b[0mweight\u001b[0m  \u001b[1;36m1.0\u001b[0m     \u001b[1;36m0.8\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4162\u001b[0m         \"\"\"\n\u001b[1;32m-> 4163\u001b[1;33m         return super().drop(\n\u001b[0m\u001b[0;32m   4164\u001b[0m             \u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4165\u001b[0m             \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   3885\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3886\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3887\u001b[1;33m                 \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3888\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3889\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[1;34m(self, labels, axis, level, errors)\u001b[0m\n\u001b[0;32m   3919\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3920\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3921\u001b[1;33m                 \u001b[0mnew_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3922\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3923\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   5280\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5281\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m\"ignore\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5282\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"{labels[mask]} not found in axis\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5283\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5284\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['latitiude'] not found in axis\""
     ]
    }
   ],
   "source": [
    "# Label encode the target variable\r\n",
    "status_labels = {'status_group':{'non functional': 0, 'functional': 1, 'functional needs repair': 2}}\r\n",
    "df = df.replace(status_labels)\r\n",
    "df.status_group.value_counts()\r\n",
    "\r\n",
    "\r\n",
    "# Drop redundant and unneeded columns\r\n",
    "to_drop = ['scheme_name', 'recorded_by', 'wpt_name', 'extraction_type', 'extraction_type_group',\r\n",
    "           'region_code', 'district_code', 'lga', 'ward', 'public_meeting', 'date_recorded', \r\n",
    "           'source_type', 'source_class', 'waterpoint_type', 'water_quality', 'management_group', \r\n",
    "           'payment', 'quantity_group','subvillage', 'num_private', 'scheme_management', 'amount_tsh', 'latitude', 'longitude']\r\n",
    "\r\n",
    "\r\n",
    "# Deal with missing values\r\n",
    "df.drop(to_drop, axis=1, inplace=True)\r\n",
    "df.permit.fillna(False, inplace=True)\r\n",
    "df.dropna(axis=0, inplace=True)\r\n",
    "\r\n",
    "# Set 'id' as the index of the dataframe\r\n",
    "df.set_index('id', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.gps_height"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grouping and Labeling Column Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funder\n",
    "df.funder.replace(to_replace='0', value='unknown', inplace=True)\n",
    "df.funder.value_counts().head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "other = list(df.funder[df['funder'].map(df['funder'].value_counts()) < 484].values)\n",
    "other\n",
    "df['funder'].replace(other, 'other', inplace=True)\n",
    "\n",
    "df.funder.replace(to_replace='0', value='Unknown', inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installer\n",
    "\n",
    "other = list(df.installer[df['installer'].map(df['installer'].value_counts()) < 392].values)\n",
    "other\n",
    "df['installer'].replace(other, 'other', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Population\n",
    "\n",
    "df['population'].replace(to_replace = 0 , value =df.population.mean(), inplace=True)\n",
    "# Areas usually don't have zero population,so we are going to replace those values with the mean!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Permit\n",
    "\n",
    "df.permit.replace({True:1, False:0}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Population\r\n",
    "    \r\n",
    "# def population(obs):\r\n",
    "#     s=''\r\n",
    "#     x=obs['population']\r\n",
    "#     if(0<x<=100):\r\n",
    "#         s='Less than 100'\r\n",
    "#     elif(100<x<=200):\r\n",
    "#         s='Between 100 and 200'\r\n",
    "#     elif(200<x<=300):\r\n",
    "#         s='Between 200 and 300'\r\n",
    "#     elif(300<x<=400):\r\n",
    "#         s='between 300 and 400'\r\n",
    "#     elif(400<x<=500):\r\n",
    "#         s='between 400 and 500'\r\n",
    "#     elif(500<x):\r\n",
    "#         s='Over 500'\r\n",
    "#     elif(x==0):\r\n",
    "#         s='No population'\r\n",
    "#     return s\r\n",
    "# df['population']=df.apply(population,axis=1)\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can potentially group the population into the bins described above. Simply run the code to do so. Investigating if it improves model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construction year\n",
    "\n",
    "\n",
    "conditions = [df['construction_year']==0, (df['construction_year']>=1960)&(df['construction_year']<=1970), (df['construction_year']>1970)&(df['construction_year']<=1980),\n",
    "            (df['construction_year']>1980)&(df['construction_year']<=1990), (df['construction_year']>1990)&(df['construction_year']<=2000),\n",
    "            (df['construction_year']>2000)&(df['construction_year']<=2010), df['construction_year']>2010]\n",
    "choices = ['no_construction_year', '1960_1970', '1971_1980', '1981_1990', '1991_2000', '2001_2010', '2011_over']\n",
    "df['construction_year'] = np.select(conditions, choices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Amount_tsh\r\n",
    "# # Bin\r\n",
    "# conditions = [df.amount_tsh==0,(df.amount_tsh>0)&(df.amount_tsh<=10),(df.amount_tsh>10)&(df.amount_tsh<=100), (df.amount_tsh>100)&(df.amount_tsh<=1000),\r\n",
    "#              (df.amount_tsh>1000)&(df.amount_tsh<=2000), (df.amount_tsh>2000)&(df.amount_tsh<=10000), (df.amount_tsh>10000)&(df.amount_tsh<=100000),\r\n",
    "#              df.amount_tsh>100000]\r\n",
    "# choices = ['zero', '1 to 10', '11 to 100', '101 to 1k', '1k to 2k', '2k to 10k', '10k to 100k', 'greater than 100k']\r\n",
    "# df['amount_tsh'] = np.select(conditions, choices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.gps_height = pd.qcut(df.gps_height, 8, duplicates='drop', \n",
    "        labels=['-90m - sea level', 'sea level to 46m', '46m to 393m', '393m to 1017m', '1017m to 1316m', '1316m to 1586.75m', '1586.75m to 2770m'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# More visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.loc[df['funder']== 'Government Of Tanzania']\n",
    "df2 = df.loc[df['funder']== 'Tasaf']              \n",
    "df3 = df.loc[df['funder']== 'Danida'] \n",
    "df4 = df.loc[df['funder']== 'Hesawa'] \n",
    "df5 = df.loc[df['funder']== 'Rwssp'] \n",
    "df6 = df.loc[df['funder']== 'World Bank'] \n",
    "df7 = df.loc[df['funder']== 'Kkkt'] \n",
    "df8 = df.loc[df['funder']== 'World Vision']\n",
    "df9 = df.loc[df['funder']== 'Unicef'] \n",
    "df10 = df.loc[df['funder']== 'unknown'] \n",
    "df11 = df.loc[df['funder']== 'District Council'] \n",
    "df12 = df.loc[df['funder']== 'Dhv'] \n",
    "df13 = df.loc[df['funder']== 'Private Individual'] \n",
    "df14 = df.loc[df['funder']== 'Dwsp'] \n",
    "df15 = df.loc[df['funder']== 'Norad'] \n",
    "df16 = df.loc[df['funder']== 'Germany Republi']\n",
    "df17 = df.loc[df['funder']== 'Tcrs']\n",
    "df18 = df.loc[df['funder']== 'Ministry Of Water']\n",
    "df19 = df.loc[df['funder']== 'Water']\n",
    "df20 = df.loc[df['funder']== 'Dwe']\n",
    "\n",
    "top_20 = pd.concat([df1,df2,df3,df4,df5,df6,df7,df8,df9,df10,df11,df12,\n",
    "                    df13,df14,df15,df16,df17,df18,df19,df20], ignore_index=True)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20,20))\n",
    "sns.countplot(x='funder', hue=\"status_group\", data=top_20)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Who funded the well has a considerable effect on the functionality of it. The Government of Tanzania, Hesawa, World Bank, Tcrs, Ministry of Water (ironically), and DWE have funded a majority of wells that were non-functional at the time this data was recorded. Overall, it seems as if private individuals and the Germany Republic funded wells that had the highest ratio of functional to non-functional at the time this data was recorded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(25,25))\n",
    "sns.countplot(x='population', hue='status_group', data=df)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The lower the population, the more wells are present, most likely due to the fact that Tanzania is still composed of villages and hamlets with low urbanization. The less people around a well, the higher the likelihood of the well being functional. This could be attributed to the possibility that overuse results in non-functionality. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,12))\n",
    "sns.scatterplot(x='latitude', y='longitude', hue='status_group',data=df)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Latitude and longitude data is displayed above. There are certain areas that seem to have more functional or non-functional wells. This could provide useful classification for our model based on specific location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,12))\r\n",
    "sns.countplot(x='gps_height', hue='status_group',data=df)\r\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Locations at or below sea level seem to have a higher number of functional wells. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NEED TO USE GEOPANDAS TO UNDERSTAND THIS BETTER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.status_group.value_counts().plot(kind='bar', color='orange')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a clear class imbalance for our target variable. We will have to deal with this during our modeling.\n",
    "\n",
    "\n",
    "Potential methods:\n",
    "- SMOTE\n",
    "- Undersampling\n",
    "- Ensemble methods\n",
    "- Cost-sensitive algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries/Modules, Define Variables, OneHotEncode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, RobustScaler\r\n",
    "from sklearn.impute import MissingIndicator, SimpleImputer\r\n",
    "from sklearn.dummy import DummyClassifier\r\n",
    "from sklearn.linear_model import LogisticRegression\r\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_validate, GridSearchCV\r\n",
    "from sklearn.feature_selection import SelectFromModel\r\n",
    "from xgboost import XGBClassifier\r\n",
    "from sklearn.naive_bayes import MultinomialNB\r\n",
    "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier\r\n",
    "from sklearn.tree import DecisionTreeClassifier\r\n",
    "from sklearn.svm import SVC\r\n",
    "from sklearn.feature_selection import RFE\r\n",
    "from imblearn.pipeline import make_pipeline\r\n",
    "from imblearn.over_sampling import SMOTE\r\n",
    "\r\n",
    "\r\n",
    "# plot_confusion_matrix is a handy visual tool, added in the latest version of scikit-learn\r\n",
    "# if you are running an older version, comment out this line and just use confusion_matrix\r\n",
    "\r\n",
    "from sklearn.metrics import plot_confusion_matrix, f1_score\r\n",
    "from sklearn.metrics import confusion_matrix\r\n",
    "from sklearn.metrics import plot_roc_curve\r\n",
    "from sklearn.metrics import make_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify features and target\r\n",
    "features = df.drop('status_group', axis=1)\r\n",
    "target = df.status_group\r\n",
    "\r\n",
    "# Dummy the features\r\n",
    "features_dummied = pd.get_dummies(features, drop_first=True)\r\n",
    "features_dummied.head()\r\n",
    "\r\n",
    "# OneHotEncode the features\r\n",
    "encoder = OneHotEncoder()\r\n",
    "features_ohe = encoder.fit_transform(features)\r\n",
    "df_ohe = encoder.fit_transform(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_ohe, target, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build model\n",
    "tree = DecisionTreeClassifier(random_state=123)\n",
    "\n",
    "# Train model\n",
    "tree.fit(X_train, y_train)\n",
    "\n",
    "# Score model\n",
    "tree.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_ohe, target, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build model\n",
    "forest = RandomForestClassifier(random_state=123)\n",
    "\n",
    "# Train model\n",
    "forest.fit(X_train, y_train)\n",
    "\n",
    "# Score model\n",
    "forest.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_ohe, target, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build model\n",
    "nb = MultinomialNB()\n",
    "\n",
    "# Train model\n",
    "nb.fit(X_train, y_train)\n",
    "\n",
    "# Score model\n",
    "nb.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_col = list(df[['longitude', 'latitude']].columns)\r\n",
    "cat_col = list(df.drop(['longitude', 'latitude', 'status_group'], axis=1).columns)\r\n",
    "import category_encoders as ce\r\n",
    "from sklearn.compose import ColumnTransformer\r\n",
    "# cat_col_ohe = encoder.fit_transform(cat_col)\r\n",
    "# cat_col_ohe_df = pd.DataFrame(cat_col)\r\n",
    "# df_model = df\r\n",
    "# scaler = RobustScaler()\r\n",
    "# df[num_col]=scaler.fit_transform(df[num_col])\r\n",
    "# df[cat_col]=encoder.fit_transform(df[cat_col])\r\n",
    "\r\n",
    "# choosing scaler and encoder\r\n",
    "scaler=RobustScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.longitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.gps_height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and test sets\r\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_ohe, target, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Build model\r\n",
    "X_resampled, y_resampled = SMOTE(sampling_strategy='minority', random_state = 123).fit_sample(X_train, y_train)\r\n",
    "xg = XGBClassifier(random_state=123, objective = 'multi:softmax', num_class=3, verbosity=1, n_jobs=-1)\r\n",
    "\r\n",
    "# # # Train model\r\n",
    "# xg.fit(X_resampled, y_resampled)\r\n",
    "\r\n",
    "# # # Score model\r\n",
    "# y_preds = xg.predict(X_test)\r\n",
    "\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # Train model\r\n",
    "xg.fit(X_resampled, y_resampled)\r\n",
    "\r\n",
    "# # # Score model\r\n",
    "xg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'max_depth': [12, 16, 24] ,\n",
    "    'n_estimators': [160, 220, 250],\n",
    "    'learning_rate': [0.12, 0.001, 0.01, 0.05]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(\n",
    "    estimator=xg,\n",
    "    param_grid=parameters,\n",
    "    n_jobs = 10,\n",
    "    cv = 5,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I did not get a good score the first time around.\n",
    "0.78814"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "02a9839076075b91ad0ca4473d7f7ceb754ea3983ec7c01053cc622904b7a0ac"
  },
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "name": "python",
   "version": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}