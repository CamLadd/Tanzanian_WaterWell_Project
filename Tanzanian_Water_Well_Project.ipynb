{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Summary and Goal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tanzania, as a developing country, struggles with providing clean water to its population of over 57,000,000. There are many waterpoints already established in the country, but some are in need of repair while others have failed altogether."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build a classifier to predict the condition of a water well, using information provided in the data. This information includes:\r\n",
    "- Date\r\n",
    "- Location\r\n",
    "- Source\r\n",
    "- Funder\r\n",
    "- And more!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This data is from the DrivenData.org website. It is part of the \"Pump It Up: Data Mining the Water Table\" dfetition. DrivenData decided to split the data up into two sets, the \"Training Set\" and the \"Test Set\". \r\n",
    "\r\n",
    "It is implied by the names that we are to use the training set for creating our models, and the test set to test them. For this project, we considered merging the two dataframes in order to have more data to work with, however there are 59,400 entries in the training set and therefore more than enough to make good predicitons. \r\n",
    "\r\n",
    "If our models are subpar, we may merge the tables to aquire more data points to potentially improve model efficacy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Pandas\r\n",
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import seaborn as sns\r\n",
    "from warnings import simplefilter\r\n",
    "\r\n",
    "# ignore all future warnings\r\n",
    "simplefilter(action='ignore', category=FutureWarning)\r\n",
    "\r\n",
    "# Load data into  Pandas dataframes\r\n",
    "status_groups = pd.read_csv('status_groups.csv')\r\n",
    "testset = pd.read_csv('test_set.csv')\r\n",
    "df = pd.read_csv('training_set.csv')\r\n",
    "\r\n",
    "\r\n",
    "# Let's add our target series to the dataframe!\r\n",
    "status_groups.drop(['id'], axis=1, inplace=True)\r\n",
    "df = pd.concat([df, status_groups], axis=1)\r\n",
    "\r\n",
    "# Analyze shape of dataset\r\n",
    "print(f'Shape of dataset: {df.shape}')\r\n",
    "# display(df.head())\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop unneeded columns and deal with missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\r\n",
    "# Create column that shows the age of the well at the time of recording\r\n",
    "\r\n",
    "\r\n",
    "from datetime import datetime\r\n",
    "df['date_recorded'] = pd.to_datetime(df['date_recorded'])\r\n",
    "recorded_year = [x.year for x in df.date_recorded]\r\n",
    "df['well_age'] = recorded_year - df.construction_year\r\n",
    "# df.well_age.value_counts()\r\n",
    "# df['well_age'][df.well_age<0]\r\n",
    "# df.iloc[[10441, 8729, 13366, 23373, 27501, 32619, 33942, 39559]][['construction_year', 'date_recorded', 'status_group']]\r\n",
    "\r\n",
    "\r\n",
    "# Interestingly enough, there are some negative values for the age of wells\r\n",
    "# This indicates that the well was PLANNED on being built at the time of recording, but had not yet been recorded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXPLORATORY! We are analyzing the columns in order to remove redundancies\r\n",
    "# **Uncomment if viewing the unique values is desired**\r\n",
    "\r\n",
    "# df.region.unique()\r\n",
    "# df.scheme_management\r\n",
    "\r\n",
    "# display(df['extraction_type_class'].unique())\r\n",
    "# display(df['extraction_type'].unique())\r\n",
    "# display(df['extraction_type_group'].unique())\r\n",
    "\r\n",
    "# display(df['source_class'].unique())\r\n",
    "# display(df['source'].unique())\r\n",
    "# display(df['source_type'].unique())\r\n",
    "\r\n",
    "# display(df.waterpoint_type.unique())\r\n",
    "# display(df.waterpoint_type_group.unique())\r\n",
    "\r\n",
    "# display(df.water_quality.unique())\r\n",
    "# display(df.quality_group.unique())\r\n",
    "\r\n",
    "# display(df.management.unique())\r\n",
    "# display(df.management_group.unique())\r\n",
    "\r\n",
    "# display(df.payment.unique())\r\n",
    "# display(df.payment_type.unique())\r\n",
    "\r\n",
    "# display(df.quantity.unique())\r\n",
    "# display(df.quantity_group.unique())\r\n",
    "\r\n",
    "df.isna().sum()[df.isna().sum()>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label encode the target variable\r\n",
    "status_labels = {'status_group':{'non functional': 0, 'functional': 1, 'functional needs repair': 2}}\r\n",
    "df = df.replace(status_labels)\r\n",
    "df.status_group.value_counts()\r\n",
    "\r\n",
    "# Organize the funder column a little based on occurence\r\n",
    "low_occurence = list(df.funder[df['funder'].map(df['funder'].value_counts()) < 100].values)\r\n",
    "df['funder'].replace(low_occurence, 'other', inplace=True)\r\n",
    "\r\n",
    "# Drop redundant and unneeded columns\r\n",
    "to_drop = ['scheme_name', 'recorded_by', 'wpt_name', 'extraction_type', 'extraction_type_group',\r\n",
    "           'region_code', 'district_code', 'latitude', 'longitude', 'lga', 'ward', 'public_meeting', 'date_recorded', \r\n",
    "           'source', 'source_type', 'waterpoint_type', 'water_quality', 'management_group', \r\n",
    "           'payment', 'quantity_group','subvillage', 'num_private', 'construction_year']\r\n",
    "\r\n",
    "# Deal with missing values\r\n",
    "df.drop(to_drop, axis=1, inplace=True)\r\n",
    "df.scheme_management.replace({'None':'Ignore', np.nan:'Ignore'}, inplace=True)\r\n",
    "df.permit.fillna(False, inplace=True)\r\n",
    "df.dropna(axis=0, inplace=True)\r\n",
    "\r\n",
    "# Set 'id' as the index of the dataframe\r\n",
    "df.set_index('id', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grouping and Labeling Column Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Permit\r\n",
    "\r\n",
    "df.permit.replace({True:1, False:0}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Population\r\n",
    "    \r\n",
    "def population(obs):\r\n",
    "    s=''\r\n",
    "    x=obs['population']\r\n",
    "    if(0<x<=100):\r\n",
    "        s='Less than 100'\r\n",
    "    elif(100<x<=200):\r\n",
    "        s='Between 100 and 200'\r\n",
    "    elif(200<x<=300):\r\n",
    "        s='Between 200 and 300'\r\n",
    "    elif(300<x<=400):\r\n",
    "        s='between 300 and 400'\r\n",
    "    elif(400<x<=500):\r\n",
    "        s='between 400 and 500'\r\n",
    "    elif(500<x):\r\n",
    "        s='Over 500'\r\n",
    "    elif(x==0):\r\n",
    "        s='No population'\r\n",
    "    return s\r\n",
    "df['population']=df.apply(population,axis=1)\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Well_age\r\n",
    "\r\n",
    "# Drop all items that have a value less than 0 (very few)\r\n",
    "df.drop(df[df['well_age'] < 0].index, inplace = True)\r\n",
    "\r\n",
    "# Bin\r\n",
    "conditions = [df.well_age==0, (df.well_age>0)&(df.well_age<=4), (df.well_age>4)&(df.well_age<=12), (df.well_age>12)&(df.well_age<=25), \r\n",
    "              (df.well_age>25)&(df.well_age<=48), df.well_age>48]\r\n",
    "choices = ['new', '0-4 years', '4-12 years', '12-25 years', '25-48 years', 'more than 48 years']\r\n",
    "df['well_age'] = np.select(conditions, choices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Amount_tsh\r\n",
    "# Bin\r\n",
    "conditions = [df.amount_tsh==0,(df.amount_tsh>0)&(df.amount_tsh<=10),(df.amount_tsh>10)&(df.amount_tsh<=100), (df.amount_tsh>100)&(df.amount_tsh<=1000),\r\n",
    "             (df.amount_tsh>1000)&(df.amount_tsh<=2000), (df.amount_tsh>2000)&(df.amount_tsh<=10000), (df.amount_tsh>10000)&(df.amount_tsh<=100000),\r\n",
    "             df.amount_tsh>100000]\r\n",
    "choices = ['zero', '1 to 10', '11 to 100', '101 to 1k', '1k to 2k', '2k to 10k', '10k to 100k', 'greater than 100k']\r\n",
    "df['amount_tsh'] = np.select(conditions, choices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.gps_height = pd.qcut(df.gps_height, 8, duplicates='drop', \r\n",
    "        labels=['-90m - sea level', 'sea level to 46m', '46m to 393m', '393m to 1017m', '1017m to 1316m', '1316m to 1586.75m', '1586.75m to 2770m'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(target, stat='density')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.population.value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.well_age.value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify features and target\r\n",
    "features = df.drop('status_group', axis=1)\r\n",
    "target = df.status_group\r\n",
    "\r\n",
    "# Dummy the features\r\n",
    "pd.get_dummies(cats, drop_first=True)\r\n",
    "\r\n",
    "# Split the data\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "X_train, y_train, X_test, y_test = train_test_split(features, target, random_state=33)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "02a9839076075b91ad0ca4473d7f7ceb754ea3983ec7c01053cc622904b7a0ac"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('learn-env': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}